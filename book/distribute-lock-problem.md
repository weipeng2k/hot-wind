# 实现分布式锁会遇到的问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁与（类似**JUC**的）单机锁区别在于：**资源状态**由进程内转移到进程外，访问**资源状态**的方式由本地调用转换成为网络调用，这些变化会带来巨大的问题（与挑战），主要体现在**4**个方面：性能、正确性、可用性以及成本。

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-implement-problem.jpg">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们先考虑一种最简单的分布式锁实现方案，它依赖一个关系数据库（比如：**MySQL**，以下简称为：数据库）来维护**资源状态**，可以称为数据库分布式锁。数据库具备事务特性，因此能够支持原子化的新增和删除，同时依靠唯一约束和**Where**条件，使之可以成为一个良好的分布式锁**存储服务**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据库中，创建一张*lock*表，它的主要字段以及运作过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到图中**实例A**和**B**在尝试获取一个名为*order_lock*的锁，获取锁的方式就是在*lock*表中成功新增一行当前锁与实例对应的记录。*lock*表包含了两个关键字段，一个是代表锁资源的*lock_name*，在该字段上建有唯一约束，另一个是代表获取到锁的客户端（或实例）*client*。不同的分布式锁会有不同的名称，而这个名称就是锁资源，它保存在*lock_name*中，一旦客户端获取到了某个名称的分布式锁，它的信息会被保存在*client*中，这表明了这把锁的所属，可以选择保存客户端的**IP**。

> *client*的值如果要确保严谨，可以选择**IP**+进程ID+线程ID，这里简单起见，还是选择**IP**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果客户端需要获取锁，就必须在表中成功增加一行记录，如果增加记录成功，则表示该客户端成功的获取到了锁，如果由于主键冲突错误而导致增加失败，则需要不断自旋重试。*lock*表在*lock_name*一列上存在唯一约束，所以同一时刻只会有一个实例（图中为：**实例A**）能够完成新增记录，从而获取到*order_lock*锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当客户端完成操作，需要释放锁时，需要客户端根据锁名称和**IP**删除之前创建的记录。*lock*表中*client*字段，它记录了当前客户端的**IP**，目的是在删除时，通过**SQL**语句`DELETE FROM LOCK WHERE LOCK_NAME = ? AND CLIENT=?`来保证只有拥有锁的**实例A**才能释放锁，防止其他实例误释放锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个简单的分布式锁看起来（实际上也）是可以完成分布式环境下并发控制工作，接下来介绍实现分布式锁遇到的问题，并基于这些问题，再次审视这个锁。

## 性能问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用分布式锁时，会给系统带来一定的性能损失。不论是单机锁还是分布式锁，在实现锁时，都需要获取锁的**资源状态**，然后进行比对。如果是单机锁，只需要读取内存中的值，而分布式锁则需要网络上的一来一回获取远端的值。分布式锁的性能理论上弱于单机锁，而不同分布式锁性能与其**存储服务**性能以及网络协议有关。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用网络来获取**资源状态**对性能有多大影响呢？这里通过访问不同设备的延迟数据来直观的感受一下，如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-access-equipment.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图参考自**Jeff Dean**发表的 *《Numbers Everyone Should Know》* 2020版。通过观察该图可以发现，访问**CPU**的缓存是纳秒级别，访问内存在百纳秒级别，而在一个数据中心内往返一次在百微秒（或毫秒）级别，一旦跨数据中心将会到达到（甚至超过）百毫秒级别。可以看到单机锁能提供纳秒级别的延迟，而分布式锁的延迟会在毫秒级别，二者存在上千倍差距。

> 分布式锁的**存储服务**一般会与应用部署在同一个数据中心。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果网络变得更快会不会提升分布式锁的性能呢？答案是肯定，但也是存在极限的。从*1990*年开始到*2020*年，*30*年的时间里，计算机访问不同设备的速度有了巨大提升。访问网络的延迟虽然有了很大改善，但是趋势在逐渐变缓，也就是说硬件与工艺提升带来的红利变得很微薄，提升不足以引起质变。

> 历年访问不同设备的延迟数据，可以参考[这里](https://colin-scott.github.io/personal_website/research/interactive_latency.html)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于分布式锁在访问**存储服务**上比单机锁有显著的延迟，所以就锁的性能而言，肯定是低于单机锁的。当然会有同学提出，单机锁不是解决不了分布式环境下的并发控制问题吗？没错，这里就访问延迟来比较二者的性能有所偏颇，但需要读者明白，分布式锁的引入并不是系统高性能的保证，不见得分布式会比单机更加有效率，使用分布式锁就需要接受它带来的延迟，因为它的目的是为分布式环境中水平伸缩的应用服务提供并发控制能力，保障逻辑执行的正确性。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的分布式锁实现会依赖不同的**存储服务**，比如：**Redis**或**ZooKeeper**，它们之间的性能也是存在差异的，主要体现在传输协议大小、**I/O**链路是否非阻塞和功能实现上。传输协议是指客户端与**存储服务**通信时有格式的二进制数据，一般来说相同类型操作协议体积越小，性能越好。**I/O**链路是指客户端与**存储服务**通信的模式，一般非阻塞**I/O**会优于同步**I/O**，在支持客户端数量上，前者有显著优势。功能实现主要是**存储服务**自身实现的复杂度，复杂度越高，性能就会越低，一般来说，越是通用的存储实现，其复杂度会更高。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于数据库分布式锁而言，客户端与**存储服务**（也就是关系数据库）通信时传输的是各数据库提供商的专属协议，但由于包含了**SQL**，所以就协议体积而言，数据库分布式锁传输协议体积是比较大的。在**I/O链路**上，数据库分布式锁使用同步**I/O**进行通信，因此支持的客户端额定数量较少。数据库由于其通用性，其实现相对复杂，比如：涉及到**SQL**解析，索引选择等处理步骤，因此在耗时上较多。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到数据库分布式锁的性能较差，所以它适合客户端少，并发度以及访问量较低的场景，比如：防止后台任务并行运行的工作。

## 正确性问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁的正确性是指，能够保证锁在任意时刻不会被两个（或多于两个以上）客户端同时持有的特性。如果使用过类似**JUC**的单机锁，一定会觉得保证正确性对于锁而言，不是应该很容易做到的吗？在认为容易之前，先回顾一下在单机锁中是如何保证正确性的。单机锁是依靠**CAS**操作来进行锁**资源状态**的设置，如果客户端能够设置成功，才被认为获得了锁。

> 关于**JUC**单机锁的实现原理，在[《Java并发编程的艺术》](http://product.dangdang.com/23745571.html)中第五章会有详细介绍，想更细致了解的同学可以选择更深入的阅读。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于单机锁的**CAS**操作是由系统指令保证，链路极短且可靠，并且**资源状态**由锁本身维护，从而能够确保其正确性。分布式锁的**资源状态**在**存储服务**上，而**存储服务**会以开放形式部署在数据中心里，如果有其他客户端非法删除了**资源状态**，而恰好此时有另一个客户端尝试获取锁，这就造成两个客户端都能获取到锁，导致**同步逻辑**无法被保护。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;有同学会问，我的**存储服务**管理的很好，只有自己的应用使用，这样是不是就没有正确性问题了？客观的讲，专有专用确实提升了正确性，但非法删除**资源状态**的“凶手”不见得是其他团队的应用，还有可能是**存储服务**自己。在使用存储服务时，出于保障可用性考虑，一般会使用主从结构的部署方式。考虑一种情况：如果主节点宕机，主从会进行（自动）切换，而主从之间的数据同步由于存在延迟，这会使得另一个客户端在访问新晋升的主节点时，有概率无法看到“已有”的某些**资源状态**，进而成功获取到锁，导致正确性再次被违反。

> **存储服务**的主从切换对分布式锁正确性的影响，在[拉模式的分布式锁](https://weipeng2k.github.io/hot-wind/book/distribute-lock-spin-impl.html)中会详细的介绍。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，纵使有专用的**存储服务**，也无法完全确保分布式锁的正确性。绝对的正确性是无法做到的，不同的分布式锁实现由于其**存储服务**的不同，正确性保障也有强弱之分。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据库分布式锁的正确性保障是比较高的，依托于经典的关系数据库，纵使主从复制带来的问题，也能得到较好的解决，比如：**MySQL**可以通过开启半同步复制，牺牲一些同步效率来确保主从数据的一致性，进而提升了分布式锁的正确性保障。

## 可用性问题

局部和全局，局部不会出现死锁，全局不会出现不可用

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁除了面对由于链路变化导致出现的延迟问题之外，还需要考虑锁**资源状态**的可靠性问题。由于锁**资源状态**放置在远程存储上，所以它的管理是依靠（使用锁的）进程实例（或线程）的网络请求来完成的，这个过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-remote-status.png" width="70%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在单机锁中，锁的**资源状态**和应用实例是一体的，而分布式锁的**资源状态**与应用实例相互独立，这会带来锁资源占用超时的问题。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述锁看起来可以完成分布式并发控制的工作，但它实际上存在超时问题。假设一种场景，实例在获取到锁后，由于异常导致没有释放锁（可能是没有释放锁或系统错误导致实例崩溃），但锁记录仍旧存在，这会使得再也没有实例可以获取到锁，分布式系统进入死锁状态。解决分布式锁可能带来的死锁问题，最直接的办法是增加锁记录的超时时间，通过增加占用锁的最长时间这一约束，从而避免分布式系统陷入死锁的窘境。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以通过在`lock`表中新增一个`expire_time`字段，每次实例获取到锁时需要设置超时时间，当超时时间到达时，将会删除该记录，纵使可能会违反锁的排他性，导致两个实例同时执行，也不能使系统存在死锁的风险。清除超时锁记录的工作可以交给一个专属的应用实例去完成，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql-expire-time.png" width="90%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，可以通过一个分布式锁超时清除实例来定时的清除过期的锁记录，这样做的好处在于不需要将是否过期的判断强行放置在应用实例获取锁的逻辑中，但需要保障这个清除实例的可用性。应用实例在获取锁时，需要将过期时间计算好，一般是当前时间加上一个超时时间差，至于这个时间差需要设置多少，需要结合应用获取锁后执行逻辑的最大耗时来考虑，也就是说时间差设置长短的问题还是抛给了分布式锁的使用者。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过增加分布式锁的占用超时时间，可以有效的避免由于实例自身稳定性问题而导致分布式锁**资源状态**没有正常释放的问题。使用一个超时清除实例来定期删除过期的锁记录，可以有效的避免超时问题带来的死锁，但总感觉有些累赘。可以使用**Redis**之类的缓存系统来存放锁的**资源状态**，通过设置缓存的过期时间，不仅能够完成过期锁记录的自动删除，还使得超时响应变得更加及时。

## 成本问题
