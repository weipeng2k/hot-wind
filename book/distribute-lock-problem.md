# 实现分布式锁会遇到的问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁与（类似**JUC**的）单机锁区别在于：**资源状态**由进程内转移到进程外，访问**资源状态**的方式由本地调用转换成为网络调用，这些变化会带来巨大的问题（与挑战），主要体现在**4**个方面：性能、正确性、可用性以及成本。

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-implement-problem.jpg">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们先考虑一种最简单的分布式锁实现方案，它依赖一个关系数据库（比如：**MySQL**，以下简称为：数据库）来维护**资源状态**，可以称为数据库分布式锁。数据库具备事务特性，因此能够支持原子化的新增和删除，同时依靠唯一约束和**Where**条件，使之可以成为一个良好的分布式锁**存储服务**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据库中，创建一张*lock*表，它的主要字段以及运作过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到图中**实例A**和**B**在尝试获取一个名为*order_lock*的锁，获取锁的方式就是在*lock*表中成功新增一行当前锁与实例对应的记录。*lock*表包含了两个关键字段，一个是代表锁资源的*lock_name*，在该字段上建有唯一约束，另一个是代表获取到锁的客户端（或实例）*client*。不同的分布式锁会有不同的名称，而这个名称就是锁资源，它保存在*lock_name*中，一旦客户端获取到了某个名称的分布式锁，它的信息会被保存在*client*中，这表明了这把锁的所属，可以选择保存客户端的**IP**。

> *client*的值如果要确保严谨，可以选择**IP**+进程ID+线程ID，这里简单起见，还是选择**IP**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果客户端需要获取锁，就必须在表中成功增加一行记录，如果增加记录成功，则表示该客户端成功的获取到了锁，如果由于主键冲突错误而导致增加失败，则需要不断自旋重试。*lock*表在*lock_name*一列上存在唯一约束，所以同一时刻只会有一个实例（图中为：**实例A**）能够完成新增记录，从而获取到*order_lock*锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当客户端完成操作，需要释放锁时，需要客户端根据锁名称和**IP**删除之前创建的记录。*lock*表中*client*字段，它记录了当前客户端的**IP**，目的是在删除时，通过**SQL**语句`DELETE FROM LOCK WHERE LOCK_NAME = ? AND CLIENT=?`来保证只有拥有锁的**实例A**才能释放锁，防止其他实例误释放锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这个简单的分布式锁看起来（实际上也）是可以完成分布式环境下并发控制工作，接下来介绍实现分布式锁遇到的问题，并基于这些问题，再次审视这个锁。

## 性能问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不论是单机锁还是分布式锁，在实现锁时，都需要获取锁的**资源状态**，然后进行比对。如果是单机锁，只需要读取内存中的值，而分布式锁则需要网络上的一来一回获取远端的值。分布式锁的性能理论上弱于单机锁，而不同分布式锁性能与其**存储服务**性能以及网络协议有关。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用网络来获取**资源状态**对性能有多大影响呢？这里通过访问不同设备的延迟数据来直观的感受一下，如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-access-equipment.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图参考自**Jeff Dean**发表的 *《Numbers Everyone Should Know》* 2020版。通过观察该图可以发现，访问**CPU**的缓存是纳秒级别，访问内存在百纳秒级别，而在一个数据中心内往返一次在百微秒（或毫秒）级别，一旦跨数据中心将会到达到（甚至超过）百毫秒级别。可以看到单机锁能提供纳秒级别的延迟，而分布式锁的延迟会在毫秒级别，二者存在上千倍差距。

> 分布式锁的**存储服务**一般会与应用部署在同一个数据中心。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果网络变得更快会不会提升分布式锁的性能呢？答案是肯定，但也是存在极限的。从*1990*年开始到*2020*年，*30*年的时间里，计算机访问不同设备的速度有了巨大提升。访问网络的延迟虽然有了很大改善，但是趋势在逐渐变缓，也就是说硬件与工艺提升带来的红利变得很微薄，提升不足以引起质变。

> 历年访问不同设备的延迟数据，可以参考[这里](https://colin-scott.github.io/personal_website/research/interactive_latency.html)

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于分布式锁在访问**存储服务**上比单机锁有显著的延迟，所以就锁的性能而言，肯定是低于单机锁的。当然会有同学提出，单机锁不是解决不了分布式环境下的并发控制问题吗？没错，这里就访问延迟来比较二者的性能有所偏颇，但需要读者明白，分布式锁的引入并不是系统高性能的保证，不见得分布式会比单机更加有效率，使用分布式锁就需要接受它带来的延迟，因为它的目的是为分布式环境中水平伸缩的应用服务提供并发控制能力，保障逻辑执行的正确性。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不同的分布式锁实现会依赖不同的**存储服务**，比如：**Redis**或**ZooKeeper**，它们之间的性能也是存在差异的，主要体现在传输协议大小、**I/O**链路是否非阻塞和功能实现上。传输协议是指客户端与**存储服务**通信时有格式的二进制数据，一般来说相同类型操作协议体积越小，性能越好。**I/O**链路是指客户端与**存储服务**通信的模式，一般非阻塞**I/O**会优于同步**I/O**，在支持客户端数量上，前者有显著优势。功能实现主要是**存储服务**自身实现的复杂度，复杂度越高，性能就会越低，一般来说，越是通用的存储实现，其复杂度会更高。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于数据库分布式锁而言，客户端与**存储服务**（也就是关系数据库）通信时传输的是各数据库提供商的专属协议，但由于包含了**SQL**，所以就协议体积而言，数据库分布式锁传输协议体积是比较大的。在**I/O链路**上，数据库分布式锁使用同步**I/O**进行通信，因此支持的客户端额定数量较少。数据库由于其通用性，其实现相对复杂，比如：涉及到**SQL**解析，索引选择等处理步骤，因此在耗时上较多。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到数据库分布式锁的性能较差，所以它适合解决客户端少，并发度以及访问量较低的场景，比如：防止后台任务并行运行的工作。

## 可用性问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁除了面对由于链路变化导致出现的延迟问题之外，还需要考虑锁**资源状态**的可靠性问题。由于锁**资源状态**放置在远程存储上，所以它的管理是依靠（使用锁的）进程实例（或线程）的网络请求来完成的，这个过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-remote-status.png" width="70%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在单机锁中，锁的**资源状态**和应用实例是一体的，而分布式锁的**资源状态**与应用实例相互独立，这会带来锁资源占用超时的问题。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述锁看起来可以完成分布式并发控制的工作，但它实际上存在超时问题。假设一种场景，实例在获取到锁后，由于异常导致没有释放锁（可能是没有释放锁或系统错误导致实例崩溃），但锁记录仍旧存在，这会使得再也没有实例可以获取到锁，分布式系统进入死锁状态。解决分布式锁可能带来的死锁问题，最直接的办法是增加锁记录的超时时间，通过增加占用锁的最长时间这一约束，从而避免分布式系统陷入死锁的窘境。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以通过在`lock`表中新增一个`expire_time`字段，每次实例获取到锁时需要设置超时时间，当超时时间到达时，将会删除该记录，纵使可能会违反锁的排他性，导致两个实例同时执行，也不能使系统存在死锁的风险。清除超时锁记录的工作可以交给一个专属的应用实例去完成，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql-expire-time.png" width="90%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，可以通过一个分布式锁超时清除实例来定时的清除过期的锁记录，这样做的好处在于不需要将是否过期的判断强行放置在应用实例获取锁的逻辑中，但需要保障这个清除实例的可用性。应用实例在获取锁时，需要将过期时间计算好，一般是当前时间加上一个超时时间差，至于这个时间差需要设置多少，需要结合应用获取锁后执行逻辑的最大耗时来考虑，也就是说时间差设置长短的问题还是抛给了分布式锁的使用者。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过增加分布式锁的占用超时时间，可以有效的避免由于实例自身稳定性问题而导致分布式锁**资源状态**没有正常释放的问题。使用一个超时清除实例来定期删除过期的锁记录，可以有效的避免超时问题带来的死锁，但总感觉有些累赘。可以使用**Redis**之类的缓存系统来存放锁的**资源状态**，通过设置缓存的过期时间，不仅能够完成过期锁记录的自动删除，还使得超时响应变得更加及时。

## 正确性问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁使用**Redis**之类的缓存系统来存储锁的资源状态，可以简化其实现方式，毕竟不需要用编程的方式来清除过期的锁记录，因为缓存系统固有的过期机制可以很好的处理这项工作。如果存储锁资源状态的服务出现故障，则会导致分布式锁服务不可用，为了确保服务的可用性，会选择使用缓存的集群技术。以**Redis**为例，使用主从集群可以提升分布式锁服务的可用性，但是它会带来正确性问题。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redis**的主从集群会确保在集群中的所有节点上保有全量数据，数据的写入由主节点进入，然后将变更异步同步到从节点。这种同步模式会导致在主从切换的一段时间内，主从节点上的数据并不对等，进而导致部分分布式锁可能被多个客户端实例同时获取到的情况，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redis-master-slave.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用**Redis**来存放分布式锁的资源状态，一般会采用字符串数据类型，其中*KEY*可以是锁的名称，*VALUE*是一个随机值，该随机值能够唯一标识出获得锁的客户端，目的是防止没有获取到分布式锁的客户端删除了锁记录。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图中保存锁资源状态的**Redis**使用了主从集群来提升锁服务的可用性，避免出现由于**Redis**节点挂掉后导致锁服务整体不可用的情况出现。虽然可用性提升了，但是正确性会下降。在**Redis**集群出现主从切换时，**实例A**先成功的在切换前的**Redis**主节点上创建了锁记录，也就是获取到了锁。随后**Redis**主节点挂掉，集群进行主从切换，锁记录数据异步的同步到新晋升的**Redis**节点上。此时**实例B**尝试获取锁，它会在新晋**Redis**主节点上创建锁记录，由于数据并未在此时完成同步，所以**实例B**成功创建锁记录并获取到了锁。在这一刻，**实例A和B**都会宣称获取到了锁，执行后续的逻辑，从而导致锁的正确性无法被满足。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果是**Redis**单节点做分布式锁的存储服务，在其能够正常服务的情况下，分布式锁的正确性能够得以满足，但可用性存在问题。而使用**Redis**主从集群技术，提升了分布式锁的可用性，但正确性又会存在风险。面对可用性和正确性两难的局面，**Redis**作者（Salvatore）设计了不基于Redis主从技术的**Redlock**算法，该算法使用多个**Redis**节点，使用基于法定人数过半（Quorum）的策略，以期望该算法能做到正确性与可用性的兼得。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**需要使用多个**Redis**节点来实现分布式锁，节点数量一般是奇数，并且至少要5个节点才能使其具备良好的可用性。同时该算法是一个客户端算法，也就是说它在每个客户端上的运行方式一致，且客户端之间不会进行相互通信。接下来以5个节点为例，**Redlock**算法过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，在客户端运行的**Redlock**算法会首先获取当前时间T，然后使用相同的锁名称*lock_name*和随机值*value*并行的向5个**Redis**节点进行操作。执行的操作与单节点**Redis**分布式锁一致，如果对应的**Redis**节点上不存在*lock_name*则会成功设置，且过期时长为*Timeout*。对5个**Redis**节点进行设置的结果分别为*R1至R5*，取当前时间*T’*，如果结果成功数量大于等于3且 *(T’-T)*小于*Timeout*，表明在多数**Redis**节点上成功设置了*lock_name*且这些*KEY*均没有过期，则客户端获取到了锁，有效期为*ET1至ET5*的最小值减去*T*。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果设置结果成功数量小于3，表明在多个**Redis**节点上，对于设置*lock_name*没有寻得共识。如果 *(T’-T)*大于等于*Timeout*，表明当前客户端获取的锁已经超时。上述两种情况一旦出现，则客户端获取锁失败。此时需要在所有**Redis**节点上运行无副作用的删除脚本，将当前客户端创建的记录（如果有的话，就）删除，避免记录要等到超时才能被清除。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**算法看起来能够在分布式锁的可用性和正确性之间寻得平衡，某个**Redis**节点挂掉，不会引起分布式锁的可用性问题，同时正确性又得以保证。理想情况下，**Redlock**看似很完美，但在分布式环境中，进程的暂停或网络的延迟，会打破该算法，使之失效。以**Java**应用为例，如果在算法判定获取到锁，客户端开始执行锁保护的逻辑前引入**GC**暂停，则会导致该算法对于正确性承诺的失效，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock-problem.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，**客户端A**获取到了锁，然后开始执行锁保护的同步逻辑，该逻辑在同一时刻只能有一个客户端能够执行。当**客户端A**开始执行逻辑时，由于**GC**导致进程出现停顿（**GC**暂停不会由于运行的是业务线程而对其特殊对待，它会一律暂停**Java**虚拟机中的除**GC**外的线程），**GC**暂停时长超出了锁的有效期，此时锁已经由于超时而释放。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**客户端B**在锁超时后获取到了锁，然后开始执行同步逻辑，**客户端A**由于**GC**结束而恢复执行，此时原本被锁保护的同步逻辑出现了并发执行，锁的正确性被违反。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到虽然**Redlock**算法通过基于法定人数的设计，在理论上确保了正确性和可用性，但是在真实的分布式环境中，会出现正确性无法确保的问题。有同学会问，如果使用没有**GC**特性的编程语言来开发应用，是不是就可以避免由于**GC**导致**Redlock**正确性无法确保的问题。实际上除了**GC**导致进程暂停，如果同步逻辑中有网络交互，也可能由于**TCP**重传等问题导致逻辑实际的执行时间超出了锁的有效期，进而导致两个客户端又有可能并发的执行同步逻辑。这个问题的本质在于基于**Redis**实现的分布式锁，对于锁的释放存在超时时间的假设，虽然避免了死锁，但是会导致锁超时（释放）的一刻，两个客户端同时有进行操作的可能，这点在理论模型上是能够说的通的，毕竟释放锁的不是锁的持有者，而是锁自己。

## 成本问题
