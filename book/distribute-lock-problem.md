# 实现分布式锁会遇到的问题

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-implement-problem.jpg">
</center>

## 分布式锁

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁，顾名思义，就是在分布式环境下使用的锁。它能够提供进程间的并发控制，当然也包括在一个进程内的并发控制，因此，就功能而言，狭义上讲，**分布式锁是可以替代一般`JUC`这种单机锁的**。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁对于锁资源的申请和占用，如下图：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-concept.png" width="70%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到，在一个实例（或进程）中存在多个线程，而多个实例都可以访问资源，访问资源的最小单位是线程，因此分布式锁控制的粒度同单机锁一样。`JUC`单机锁是否能够获取是依靠内存中的状态值来实现的，在本机内存中的状态值称为锁的**资源状态**，如果将内存中锁的资源移动到进程外，对资源进行获取的系统调用换成网络调用，单机锁不就转变成了分布式锁吗？没错，确实如此，但背后隐含了几个问题，就如同单机锁隐含了**可见性**问题一样。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**资源状态**由内到外的移动不会产生任何变化，而系统调用换成网络调用会产生巨大的变化，主要在以下三个方面：性能、超时和可用性问题，而超时问题会进一步引出死锁问题，接下来我们来看看这几个方面。

## 分布式锁的作用

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在分布式环境中，分布式锁可以保证有相同工作的多个节点，在同一时刻只有一个节点能够进行工作。节点的工作一般称为同步逻辑，它可能是一组计算或是对存储（以及外部API）的一些操作。分布式锁是一项比较实用的技术，使用它一般来说会有两个原因：提升效率或确保正确。如果需要在工作中使用到分布式锁，可以尝试问自己一个问题，如果没有分布式锁，会出现什么问题呢？如果是数据错乱，那就是为了确保正确，如果是集群中所有节点重复工作，那就是为了提升效率。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;区分使用分布式锁的原因是很重要的，因为它会让你对锁失败后产生的问题有了明确认识，同时对使用何种技术实现的分布式锁在选型上会考虑的更周全。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以Redis和ZooKeeper分别实现的分布式锁为例：前者吞吐量高，访问延时小，可用性一般，但实施成本低；后者吞吐量低，访问延时较高，可用性高，但实施成本高。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果使用分布式锁解决效率问题，那么由于偶尔锁失败造成重复计算的问题应该是可以容忍的，这时选择成本低的分布式锁方案会是一个好的选择。如果用分布式锁解决正确性问题，就需要尽可能保证分布式锁的可用性以及正确性，采用高成本的分布式锁实现方式就变得很必要了。

### 性能问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不论是单机锁还是分布式锁，在实现锁时，都需要获取锁的**资源状态**，然后进行比对，如果是单机锁，那需要读入保存在内存中的值，如果是分布式锁，则需要网络一来一回请求远端的值。这链路的变化，导致性能会出现巨大差异，我们可以通过看一下该图来理论分析一下存在的性能差距。

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/access-equipment-speed.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;该图参考自**Jeff Dean**发表的 *《Numbers Everyone Should Know》* 2020版。通过观察该图可以发现，访问CPU的缓存是在纳秒级别，访问内存在百纳秒级别，而在一个数据中心内往返一次在百微秒级别，而一旦跨数据中心将会到达百毫秒级别。从访问不同的设备的延迟可以看到，如果是单机锁，它能提供纳秒级别的延迟，而如果是分布式锁，延迟会在上百微秒也可能在毫秒级别，二者的差距至少存在上千倍。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果网络变得更快会不会提升分布式锁的性能呢？答案是肯定，但也是存在极限的。通过观察[历年的延迟数据](https://colin-scott.github.io/personal_website/research/interactive_latency.html)，从1990年开始到2020年，30年的时间里，计算机访问不同设备装置的速度有了巨大提升。可以发现网络的延迟虽然有很大改善，但是趋势在逐渐变缓，也就是说硬件与工艺提升带来的红利变得很微薄，虽然有提升，但是还不足以引起质变。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于分布式锁在访问**资源状态**相比单机锁存在巨大的延迟，就锁的性能而言肯定是低于单机锁的。当然会有同学提出，单机锁解决不了分布式环境下的并发控制问题呀。没错，这里就访问延迟来比较二者的性能有所偏颇，但需要读者明白，分布式锁的引入并不是整个系统高性能的保证，不见得分布式环境会比单机更加有效率，使用分布式锁需要接受它带来的延迟，而它的目的是为分布式环境中水平伸缩的应用服务提供并发控制能力，保障逻辑执行的正确性。

### 超时问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁除了面对由于链路变化导致出现的延迟问题之外，还需要考虑锁**资源状态**的可靠性问题。由于锁**资源状态**放置在远程存储上，所以它的管理是依靠（使用锁的）进程实例（或线程）的网络请求来完成的，这个过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-remote-status.png" width="70%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在单机锁中，锁的**资源状态**和应用实例是一体的，而分布式锁的**资源状态**与应用实例相互独立，这会带来锁资源占用超时的问题。我们先考虑一种最简单的分布式锁实现方式，依靠一个数据库来维护**资源状态**。在关系数据库（比如：MySQL）中，创建一个`lock`表，如果需要获取锁就需要在表中增加一行记录，可以根据锁的名称来查询锁，且在名称这个字段上增加了唯一约束。如果客户端能够新增一行记录，则代表它成功的获取到了锁，否则需要不断的尝试新增记录（并忽略主键冲突错误），当释放锁时需要主动的删除这行记录，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到图中**实例A**和**B**在尝试抢占一个名为`order_lock`的锁，而实例获取锁的方式是在`lock`表中成功新增一行当前锁对应的记录。由于`lock`表在`lock_name`一列上存在唯一约束，所以同一时刻只会有一个实例（也就是**实例A**）能够完成新增记录获取到锁。当实例完成操作后，需要释放锁，在当前场景下，可以通过删除这行记录来完成锁资源的释放。

> 需要注意`lock`表中`client`字段，它记录了当前实例的**IP**，目的是在删除时，通过条件语句`WHERE LOCK_NAME = ? AND CLIENT=?`来保证只有拥有锁的实例才能释放锁，防止其他实例误释放锁。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上述锁看起来可以完成分布式并发控制的工作，但它实际上存在超时问题。假设一种场景，实例在获取到锁后，由于异常导致没有释放锁（可能是没有释放锁或系统错误导致实例崩溃），但锁记录仍旧存在，这会使得再也没有实例可以获取到锁，分布式系统进入死锁状态。解决分布式锁可能带来的死锁问题，最直接的办法是增加锁记录的超时时间，通过增加占用锁的最长时间这一约束，从而避免分布式系统陷入死锁的窘境。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以通过在`lock`表中新增一个`expire_time`字段，每次实例获取到锁时需要设置超时时间，当超时时间到达时，将会删除该记录，纵使可能会违反锁的排他性，导致两个实例同时执行，也不能使系统存在死锁的风险。清除超时锁记录的工作可以交给一个专属的应用实例去完成，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-mysql-expire-time.png" width="90%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，可以通过一个分布式锁超时清除实例来定时的清除过期的锁记录，这样做的好处在于不需要将是否过期的判断强行放置在应用实例获取锁的逻辑中，但需要保障这个清除实例的可用性。应用实例在获取锁时，需要将过期时间计算好，一般是当前时间加上一个超时时间差，至于这个时间差需要设置多少，需要结合应用获取锁后执行逻辑的最大耗时来考虑，也就是说时间差设置长短的问题还是抛给了分布式锁的使用者。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过增加分布式锁的占用超时时间，可以有效的避免由于实例自身稳定性问题而导致分布式锁**资源状态**没有正常释放的问题。使用一个超时清除实例来定期删除过期的锁记录，可以有效的避免超时问题带来的死锁，但总感觉有些累赘。可以使用**Redis**之类的缓存系统来存放锁的**资源状态**，通过设置缓存的过期时间，不仅能够完成过期锁记录的自动删除，还使得超时响应变得更加及时。

### 正确性问题

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;分布式锁使用**Redis**之类的缓存系统来存储锁的资源状态，可以简化其实现方式，毕竟不需要用编程的方式来清除过期的锁记录，因为缓存系统固有的过期机制可以很好的处理这项工作。如果存储锁资源状态的服务出现故障，则会导致分布式锁服务不可用，为了确保服务的可用性，会选择使用缓存的集群技术。以**Redis**为例，使用主从集群可以提升分布式锁服务的可用性，但是它会带来正确性问题。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redis**的主从集群会确保在集群中的所有节点上保有全量数据，数据的写入由主节点进入，然后将变更异步同步到从节点。这种同步模式会导致在主从切换的一段时间内，主从节点上的数据并不对等，进而导致部分分布式锁可能被多个客户端实例同时获取到的情况，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redis-master-slave.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用**Redis**来存放分布式锁的资源状态，一般会采用字符串数据类型，其中*KEY*可以是锁的名称，*VALUE*是一个随机值，该随机值能够唯一标识出获得锁的客户端，目的是防止没有获取到分布式锁的客户端删除了锁记录。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图中保存锁资源状态的**Redis**使用了主从集群来提升锁服务的可用性，避免出现由于**Redis**节点挂掉后导致锁服务整体不可用的情况出现。虽然可用性提升了，但是正确性会下降。在**Redis**集群出现主从切换时，**实例A**先成功的在切换前的**Redis**主节点上创建了锁记录，也就是获取到了锁。随后**Redis**主节点挂掉，集群进行主从切换，锁记录数据异步的同步到新晋升的**Redis**节点上。此时**实例B**尝试获取锁，它会在新晋**Redis**主节点上创建锁记录，由于数据并未在此时完成同步，所以**实例B**成功创建锁记录并获取到了锁。在这一刻，**实例A和B**都会宣称获取到了锁，执行后续的逻辑，从而导致锁的正确性无法被满足。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果是**Redis**单节点做分布式锁的存储服务，在其能够正常服务的情况下，分布式锁的正确性能够得以满足，但可用性存在问题。而使用**Redis**主从集群技术，提升了分布式锁的可用性，但正确性又会存在风险。面对可用性和正确性两难的局面，**Redis**作者（Salvatore）设计了不基于Redis主从技术的**Redlock**算法，该算法使用多个**Redis**节点，使用基于法定人数过半（Quorum）的策略，以期望该算法能做到正确性与可用性的兼得。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**需要使用多个**Redis**节点来实现分布式锁，节点数量一般是奇数，并且至少要5个节点才能使其具备良好的可用性。同时该算法是一个客户端算法，也就是说它在每个客户端上的运行方式一致，且客户端之间不会进行相互通信。接下来以5个节点为例，**Redlock**算法过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，在客户端运行的**Redlock**算法会首先获取当前时间T，然后使用相同的锁名称*lock_name*和随机值*value*并行的向5个**Redis**节点进行操作。执行的操作与单节点**Redis**分布式锁一致，如果对应的**Redis**节点上不存在*lock_name*则会成功设置，且过期时长为*Timeout*。对5个**Redis**节点进行设置的结果分别为*R1至R5*，取当前时间*T’*，如果结果成功数量大于等于3且 *(T’-T)*小于*Timeout*，表明在多数**Redis**节点上成功设置了*lock_name*且这些*KEY*均没有过期，则客户端获取到了锁，有效期为*ET1至ET5*的最小值减去*T*。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果设置结果成功数量小于3，表明在多个**Redis**节点上，对于设置*lock_name*没有寻得共识。如果 *(T’-T)*大于等于*Timeout*，表明当前客户端获取的锁已经超时。上述两种情况一旦出现，则客户端获取锁失败。此时需要在所有**Redis**节点上运行无副作用的删除脚本，将当前客户端创建的记录（如果有的话，就）删除，避免记录要等到超时才能被清除。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**算法看起来能够在分布式锁的可用性和正确性之间寻得平衡，某个**Redis**节点挂掉，不会引起分布式锁的可用性问题，同时正确性又得以保证。理想情况下，**Redlock**看似很完美，但在分布式环境中，进程的暂停或网络的延迟，会打破该算法，使之失效。以**Java**应用为例，如果在算法判定获取到锁，客户端开始执行锁保护的逻辑前引入**GC**暂停，则会导致该算法对于正确性承诺的失效，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock-problem.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，**客户端A**获取到了锁，然后开始执行锁保护的同步逻辑，该逻辑在同一时刻只能有一个客户端能够执行。当**客户端A**开始执行逻辑时，由于**GC**导致进程出现停顿（**GC**暂停不会由于运行的是业务线程而对其特殊对待，它会一律暂停**Java**虚拟机中的除**GC**外的线程），**GC**暂停时长超出了锁的有效期，此时锁已经由于超时而释放。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**客户端B**在锁超时后获取到了锁，然后开始执行同步逻辑，**客户端A**由于**GC**结束而恢复执行，此时原本被锁保护的同步逻辑出现了并发执行，锁的正确性被违反。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到虽然**Redlock**算法通过基于法定人数的设计，在理论上确保了正确性和可用性，但是在真实的分布式环境中，会出现正确性无法确保的问题。有同学会问，如果使用没有**GC**特性的编程语言来开发应用，是不是就可以避免由于**GC**导致**Redlock**正确性无法确保的问题。实际上除了**GC**导致进程暂停，如果同步逻辑中有网络交互，也可能由于**TCP**重传等问题导致逻辑实际的执行时间超出了锁的有效期，进而导致两个客户端又有可能并发的执行同步逻辑。这个问题的本质在于基于**Redis**实现的分布式锁，对于锁的释放存在超时时间的假设，虽然避免了死锁，但是会导致锁超时（释放）的一刻，两个客户端同时有进行操作的可能，这点在理论模型上是能够说的通的，毕竟释放锁的不是锁的持有者，而是锁自己。
