# 拉模式的分布式锁

## 什么是拉模式？

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;拉模式的分布式锁，需要实例（通过客户端）以自旋的形式，主动去调用**存储服务**，根据调用结果来判断是否获取到了锁。调用的逻辑为：是否能够在存储服务中新增锁对应的**资源状态**（或一行记录），**资源状态**需要包含能够代表获取锁的实例（或线程）标识，并且该标识能够确保全局唯一，不同获取锁的实例标识各不相同。获取拉模式分布式锁的流程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-pull-mode-acquire-flow.png" width="60%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，虚线框中的流程就是获取锁的自旋过程，但在介绍它之前，先要看一下获取锁时需要确定的输入，这些输入变量的名称以及描述如下表所示：

|变量|名称|描述|
|----|----|----|
|*T*|当前时间|当前系统时间|
|*D*|超时时长|实例获取锁能够等待的最长时间|
|*TTL*|过期时长|**资源状态**在**存储服务**上存活的最长时间|
|*S*|睡眠时长|新增**资源状态**（也就是获取锁）失败需要睡眠的时长|
|*RN*|锁资源名称|分布式锁的名称，可以是某个业务编号|
|*RV*|锁资源值|获取锁的实例标识，需要保证唯一性，可以是**UUID**|

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在自旋过程中，首先需要判断是否已经超时，如果没有超时，则会调用**存储服务**的新增接口，尝试新增当前锁的**资源状态**，**资源状态**包括名称*RN*和值*RV*。**存储服务**的新增接口需要提供`addIfAbsent`语义，如果已经存在了一个*RN*的记录，则会返回新增失败，否则新增记录成功，且过期时间在*TTL*之后。该过程需要确保是原子化的，这样多个实例对相同的*RN*进行新增操作时，只会有一个能够成功，这样就兑现了锁的排他性。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果调用新增接口返回失败，这代表实例没有获取到锁，此时客户端需要不断的循环尝试新增直至成功，以此来满足实例获取锁的诉求。如果退出循环的条件只是新增**资源状态**成功，由于调用**存储服务**需要通过网络，稍有不慎会导致实例陷入长时间阻塞。因此，循环退出的条件还包括获取锁的超时时间到，每次新增**资源状态**失败可以睡眠一段时间，避免对**存储服务**产生过多无效请求。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当释放锁时，实例通过传入锁的资源名称*RN*和值*RV*来删除**资源状态**。**存储服务**的删除接口需要具备`compareAndDelete`语义，只有**资源状态**中的值与*RV*相同才能够删除，这样就使得只有获取到锁的实例才能够执行成功，并且多次执行删除操作也是无副作用的。

## 需要注意的点

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;拉模式的流程看起来是很简单的，实例通过客户端去获取锁，如果无法在**存储服务**中新增**资源状态**，就进行重试，要么超时返回，要么获取到锁。通过一个循环以及少量的时间运算与判断，通过几行代码就可以实现上述逻辑了。如果从能用的角度去看，就是这么简单，但想用的安心，就需要多考虑一点了。拉模式获取锁的主要步骤包括：访问**存储服务**（调用其新增接口）、时间运算与判断以及睡眠，其中访问**存储服务**和睡眠对实例获取锁有实际影响，接下来分析它们各自需要被关注的点。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;访问**存储服务**需要注意的点包括：请求的**I/O**超时、访问**存储服务**耗时和过期时长设置。首先，请求需要有**I/O**超时，举个例子：我们经常使用**HttpClient**去请求**Web**服务来获取数据，如果**Web**服务很慢或者网络延迟很高，调用线程就会被挂在那里很久。这个问题和访问**存储服务**一样，为了避免客户端陷入未知时长的等待，对**存储服务**的请求需要设置**I/O**超时。其次，访问**存储服务**耗时越短越好，如果访问耗时很低，会提升客户端的响应性，当然不同的**存储服务**访问耗时也会不一样，基于**Redis**的分布式锁在访问耗时上就优于数据库分布式锁。最后，过期时长支持定制，新增**资源状态**时会设置过期时长，一般来说这个时长会结合同步逻辑的最大耗时来考虑，是个固定值，比如：`10`秒。获取锁时，实例其实可以根据当前的上下文估算出可能的耗时，比如：发现**同步逻辑**中处理的列表数据包含的元素数量比平均数高一倍，如果此时能够适当增加对应的过期时长，会是一个好的选择。这就需要分布式锁框架提供**API**，能够支持实例设置过期时长，通过设置一个更大的值，就能有效减少由于过期自动释放锁而导致的正确性问题。

> 过期时长的设置只会影响到本次获取的锁，是基于请求的，不是全局性的。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;睡眠需要关注对**存储服务**产生的压力。对于睡眠而言，简单的做法是固定一个时长，比如：一旦客户端新增**资源状态**失败，就睡眠`15`毫秒。如果某个锁资源在多个实例之间有激烈的竞争，这种方式会使得未获取到锁的实例在一个较小的时间范围内同时醒来，并发起对**存储服务**的重试，无形中增加了**存储服务**的瞬时压力。如果实例中又以多线程并发的方式获取锁，会导致这个问题变得更糟，解决方式就是引入随机。可以通过指定最小睡眠时长*min*和随机睡眠时长*random*来计算本次应该睡眠的时长，每次睡眠时长不固定，只是在`[min, min + random)`内随机取值。通过随机睡眠会使重试变得离散，一定程度上减轻了对**存储服务**的压力。

## **Redis**分布式锁实现

## **Redis**分布式锁存在的问题

分布式锁使用**Redis**之类的缓存系统来存储锁的资源状态，可以简化其实现方式，毕竟不需要用编程的方式来清除过期的锁记录，因为缓存系统固有的过期机制可以很好的处理这项工作。如果存储锁资源状态的服务出现故障，则会导致分布式锁服务不可用，为了确保服务的可用性，会选择使用缓存的集群技术。以**Redis**为例，使用主从集群可以提升分布式锁服务的可用性，但是它会带来正确性问题。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redis**的主从集群会确保在集群中的所有节点上保有全量数据，数据的写入由主节点进入，然后将变更异步同步到从节点。这种同步模式会导致在主从切换的一段时间内，主从节点上的数据并不对等，进而导致部分分布式锁可能被多个客户端实例同时获取到的情况，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redis-master-slave.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用**Redis**来存放分布式锁的资源状态，一般会采用字符串数据类型，其中*KEY*可以是锁的名称，*VALUE*是一个随机值，该随机值能够唯一标识出获得锁的客户端，目的是防止没有获取到分布式锁的客户端删除了锁记录。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;上图中保存锁资源状态的**Redis**使用了主从集群来提升锁服务的可用性，避免出现由于**Redis**节点挂掉后导致锁服务整体不可用的情况出现。虽然可用性提升了，但是正确性会下降。在**Redis**集群出现主从切换时，**实例A**先成功的在切换前的**Redis**主节点上创建了锁记录，也就是获取到了锁。随后**Redis**主节点挂掉，集群进行主从切换，锁记录数据异步的同步到新晋升的**Redis**节点上。此时**实例B**尝试获取锁，它会在新晋**Redis**主节点上创建锁记录，由于数据并未在此时完成同步，所以**实例B**成功创建锁记录并获取到了锁。在这一刻，**实例A和B**都会宣称获取到了锁，执行后续的逻辑，从而导致锁的正确性无法被满足。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果是**Redis**单节点做分布式锁的存储服务，在其能够正常服务的情况下，分布式锁的正确性能够得以满足，但可用性存在问题。而使用**Redis**主从集群技术，提升了分布式锁的可用性，但正确性又会存在风险。面对可用性和正确性两难的局面，**Redis**作者（Salvatore）设计了不基于Redis主从技术的**Redlock**算法，该算法使用多个**Redis**节点，使用基于法定人数过半（Quorum）的策略，以期望该算法能做到正确性与可用性的兼得。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**需要使用多个**Redis**节点来实现分布式锁，节点数量一般是奇数，并且至少要5个节点才能使其具备良好的可用性。同时该算法是一个客户端算法，也就是说它在每个客户端上的运行方式一致，且客户端之间不会进行相互通信。接下来以5个节点为例，**Redlock**算法过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock.png" width="80%">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，在客户端运行的**Redlock**算法会首先获取当前时间T，然后使用相同的锁名称*lock_name*和随机值*value*并行的向5个**Redis**节点进行操作。执行的操作与单节点**Redis**分布式锁一致，如果对应的**Redis**节点上不存在*lock_name*则会成功设置，且过期时长为*Timeout*。对5个**Redis**节点进行设置的结果分别为*R1至R5*，取当前时间*T’*，如果结果成功数量大于等于3且 *(T’-T)*小于*Timeout*，表明在多数**Redis**节点上成功设置了*lock_name*且这些*KEY*均没有过期，则客户端获取到了锁，有效期为*ET1至ET5*的最小值减去*T*。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如果设置结果成功数量小于3，表明在多个**Redis**节点上，对于设置*lock_name*没有寻得共识。如果 *(T’-T)*大于等于*Timeout*，表明当前客户端获取的锁已经超时。上述两种情况一旦出现，则客户端获取锁失败。此时需要在所有**Redis**节点上运行无副作用的删除脚本，将当前客户端创建的记录（如果有的话，就）删除，避免记录要等到超时才能被清除。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**Redlock**算法看起来能够在分布式锁的可用性和正确性之间寻得平衡，某个**Redis**节点挂掉，不会引起分布式锁的可用性问题，同时正确性又得以保证。理想情况下，**Redlock**看似很完美，但在分布式环境中，进程的暂停或网络的延迟，会打破该算法，使之失效。以**Java**应用为例，如果在算法判定获取到锁，客户端开始执行锁保护的逻辑前引入**GC**暂停，则会导致该算法对于正确性承诺的失效，该过程如下图所示：

<center>
<img src="https://weipeng2k.github.io/hot-wind/resources/distribute-lock-brief-summary/distribute-lock-redlock-problem.png">
</center>

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如上图所示，**客户端A**获取到了锁，然后开始执行锁保护的同步逻辑，该逻辑在同一时刻只能有一个客户端能够执行。当**客户端A**开始执行逻辑时，由于**GC**导致进程出现停顿（**GC**暂停不会由于运行的是业务线程而对其特殊对待，它会一律暂停**Java**虚拟机中的除**GC**外的线程），**GC**暂停时长超出了锁的有效期，此时锁已经由于超时而释放。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**客户端B**在锁超时后获取到了锁，然后开始执行同步逻辑，**客户端A**由于**GC**结束而恢复执行，此时原本被锁保护的同步逻辑出现了并发执行，锁的正确性被违反。

&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;可以看到虽然**Redlock**算法通过基于法定人数的设计，在理论上确保了正确性和可用性，但是在真实的分布式环境中，会出现正确性无法确保的问题。有同学会问，如果使用没有**GC**特性的编程语言来开发应用，是不是就可以避免由于**GC**导致**Redlock**正确性无法确保的问题。实际上除了**GC**导致进程暂停，如果同步逻辑中有网络交互，也可能由于**TCP**重传等问题导致逻辑实际的执行时间超出了锁的有效期，进而导致两个客户端又有可能并发的执行同步逻辑。这个问题的本质在于基于**Redis**实现的分布式锁，对于锁的释放存在超时时间的假设，虽然避免了死锁，但是会导致锁超时（释放）的一刻，两个客户端同时有进行操作的可能，这点在理论模型上是能够说的通的，毕竟释放锁的不是锁的持有者，而是锁自己。
